{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7bdabb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristijonasraudys/.pyenv/versions/3.12.7/envs/hostinger-venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain_core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67f497",
   "metadata": {},
   "source": [
    "## STEP 0: Helpers\n",
    "Here I define some of the helper classes/functions for use in downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9ce494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    answer: str\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Response)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "\n",
    "def parse(output_text: str) -> str:\n",
    "    try:\n",
    "        parsed: Response = parser.parse(output_text)\n",
    "        return parsed.answer\n",
    "    except Exception as e:\n",
    "        raise e(f\"Could not parse from: {output_text!r}\")\n",
    "    \n",
    "def propose_domain_name(description, prompt, model, tokenizer):\n",
    "    prompt_specific = prompt.format(format_instructions=format_instructions)\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : prompt_specific},\n",
    "        {\"role\" : \"user\", \"content\" : f\"**business_description**:\\n{description}\"}\n",
    "    ]\n",
    "    tokenized_text_processed = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "    tokenized_text_processed = tokenizer([tokenized_text_processed], return_tensors=\"pt\")\n",
    "    tokenized_text_processed = {k: v.to(model.device) for k, v in tokenized_text_processed.items()}\n",
    "    generated_ids = model.generate(**tokenized_text_processed, max_new_tokens=1024, do_sample=False)\n",
    "    output_ids = generated_ids[0][len(tokenized_text_processed[\"input_ids\"][0]):]\n",
    "    output_text = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    output = parse(output_text)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0875e",
   "metadata": {},
   "source": [
    "## STEP 1: setting up a baseline \n",
    "\n",
    "For this tutorial, I decided to take on open-source route. Obviously, in production, it would be important to experiment with different models, but for the purpose of this preview, I decided to roll with one of the cheaper open-source flagmans, `Qwen3-4b-Instruct-2507`. Ideally, would have played with `Thinking` version but generation time is much longer so left that out too. Finally, I opted to use `transformers/langgraph` packages as they are often encountered in such scenarios. I will be asking the model to suggest single name to have it more consistent with finetuning part in further stages, to have better comparability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28596fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 37.27it/s]\n"
     ]
    }
   ],
   "source": [
    "NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "model = AutoModelForCausalLM.from_pretrained(NAME, dtype = torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b81df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_base = \"\"\"You are a creative but conceptual thinking tool whose task is to take the user provided *business_description** and try to summarize it and propose a potential domain name for their website.\n",
    "    If the description includes references to area where the company operates, take it into consideration.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Return ONLY ONE suggested domain name.\n",
    "    - Return ONLY the final answer in valid JSON format matching the schema below:\n",
    "\n",
    "    {format_instructions}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497f3fd",
   "metadata": {},
   "source": [
    "here are 10 gpt-generated business-description examples on which I will test different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f72ef621",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_testing_bd = [\n",
    "    \"A small studio in Barcelona that designs custom lamps and light fixtures. We mostly work with reclaimed wood and metal. Everything is handmade and produced in small batches.\",\n",
    "    \"We’re building an AI tool that helps small online shops write product descriptions automatically. It analyzes the photos and creates short, SEO-friendly copy. Not everything works perfectly yet, but early testers seem to like it.\",\n",
    "    \"Local dog walking service in Edinburgh. Nothing fancy — just reliable walkers and fair prices. We also send the owners small picture updates after each walk.\",\n",
    "    \"A new app that lets people rent out unused musical instruments to others in their neighborhood. Think of it like Airbnb but for guitars, violins, and keyboards. Still figuring out pricing though.\",\n",
    "    \"I’m starting an accounting service for freelancers in the US. Mostly bookkeeping, invoicing help, tax reminders, stuff like that. Everything is online and appointments can be booked through the website.\",\n",
    "    \"A boutique tea brand blending organic loose-leaf teas inspired by traditional Moroccan flavors. Each blend is hand-mixed and sold in small decorative tins.\",\n",
    "    \"We make a browser extension that automatically finds coupon codes for online stores. It applies the best one at checkout. It’s aimed at college students who want quick savings.\",\n",
    "    \"A family-owned bike repair shop located in Amsterdam. We fix all kinds of bikes and offer annual tune-up memberships. Customers can drop off their bikes or request mobile repairs.\",\n",
    "    \"An online course platform focused on teaching retirees how to use smartphones, social media, and basic digital tools. Lessons are short, friendly, and designed for absolute beginners.\",\n",
    "    \"Trying to build a marketplace for local artists to sell prints, stickers, and small handmade items. Not sure yet how to handle the shipping side, but the idea is to help them reach more people.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da295f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Description:\n",
      "A small studio in Barcelona that designs custom lamps and light fixtures. We mostly work with reclaimed wood and metal. Everything is handmade and produced in small batches.\n",
      "LLM suggestion: barcelona-lampstudio.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "We’re building an AI tool that helps small online shops write product descriptions automatically. It analyzes the photos and creates short, SEO-friendly copy. Not everything works perfectly yet, but early testers seem to like it.\n",
      "LLM suggestion: shopdesc.ai\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "Local dog walking service in Edinburgh. Nothing fancy — just reliable walkers and fair prices. We also send the owners small picture updates after each walk.\n",
      "LLM suggestion: edinburghdogwalks.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A new app that lets people rent out unused musical instruments to others in their neighborhood. Think of it like Airbnb but for guitars, violins, and keyboards. Still figuring out pricing though.\n",
      "LLM suggestion: neighborhoodinstrument\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "I’m starting an accounting service for freelancers in the US. Mostly bookkeeping, invoicing help, tax reminders, stuff like that. Everything is online and appointments can be booked through the website.\n",
      "LLM suggestion: FreelancerFinance.us\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A boutique tea brand blending organic loose-leaf teas inspired by traditional Moroccan flavors. Each blend is hand-mixed and sold in small decorative tins.\n",
      "LLM suggestion: moroccanbouquettea.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "We make a browser extension that automatically finds coupon codes for online stores. It applies the best one at checkout. It’s aimed at college students who want quick savings.\n",
      "LLM suggestion: CouponSavvy\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A family-owned bike repair shop located in Amsterdam. We fix all kinds of bikes and offer annual tune-up memberships. Customers can drop off their bikes or request mobile repairs.\n",
      "LLM suggestion: amsterdambikefix.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "An online course platform focused on teaching retirees how to use smartphones, social media, and basic digital tools. Lessons are short, friendly, and designed for absolute beginners.\n",
      "LLM suggestion: seniorsmartlearn.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "Trying to build a marketplace for local artists to sell prints, stickers, and small handmade items. Not sure yet how to handle the shipping side, but the idea is to help them reach more people.\n",
      "LLM suggestion: LocalArtMarket\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bd in manual_testing_bd:\n",
    "    print(f\"User Description:\\n{bd}\")\n",
    "    print(f\"LLM suggestion: {propose_domain_name(bd, prompt_base, model, tokenizer)}\")\n",
    "    print(\"-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b98f640",
   "metadata": {},
   "source": [
    "## STEP 2: Improving via prompt-engineering\n",
    "Okay, looking at the suggestions on the test set, we can easily notice that 2 of the examples actually are not even proper domain names: `neighborhoodinstrument`, `CouponSavvy` and `LocalArtMarket`. This is clearly not good and should be addressed in prompt engineering. Furthermore, other descriptions, while relevant, have two evident issues: \n",
    "\n",
    "1) they are straight-forward \n",
    "2) they disregard suggesting appropriate TLD in most of the cases where it could be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ecb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_improved = \"\"\"You are a creative but conceptual thinking tool whose task is to take the user provided *business_description** and try to summarize it and propose a potential domain name for their website.\n",
    "    If the description includes references to area where the company operates, take it into consideration.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Return ONLY ONE suggested domain name.\n",
    "    - If it is possible to identify the relevant location, suggest TLD based on it so that it targets customers from relevant region.\n",
    "    - Ensure that domain name is of proper format: NAME.TLD.\n",
    "    - Return ONLY the final answer in valid JSON format matching the schema below:\n",
    "\n",
    "    {format_instructions}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6bd0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Description:\n",
      "A small studio in Barcelona that designs custom lamps and light fixtures. We mostly work with reclaimed wood and metal. Everything is handmade and produced in small batches.\n",
      "LLM suggestion: lumina-barca.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "We’re building an AI tool that helps small online shops write product descriptions automatically. It analyzes the photos and creates short, SEO-friendly copy. Not everything works perfectly yet, but early testers seem to like it.\n",
      "LLM suggestion: shopdesc.ai\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "Local dog walking service in Edinburgh. Nothing fancy — just reliable walkers and fair prices. We also send the owners small picture updates after each walk.\n",
      "LLM suggestion: walkedin.educ\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A new app that lets people rent out unused musical instruments to others in their neighborhood. Think of it like Airbnb but for guitars, violins, and keyboards. Still figuring out pricing though.\n",
      "LLM suggestion: RentMusic.neighborhood\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "I’m starting an accounting service for freelancers in the US. Mostly bookkeeping, invoicing help, tax reminders, stuff like that. Everything is online and appointments can be booked through the website.\n",
      "LLM suggestion: FreelanceAccounting.US\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A boutique tea brand blending organic loose-leaf teas inspired by traditional Moroccan flavors. Each blend is hand-mixed and sold in small decorative tins.\n",
      "LLM suggestion: moroccanbouquet.tea\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "We make a browser extension that automatically finds coupon codes for online stores. It applies the best one at checkout. It’s aimed at college students who want quick savings.\n",
      "LLM suggestion: CouponSavvy.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A family-owned bike repair shop located in Amsterdam. We fix all kinds of bikes and offer annual tune-up memberships. Customers can drop off their bikes or request mobile repairs.\n",
      "LLM suggestion: bikefix.amsterdam\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "An online course platform focused on teaching retirees how to use smartphones, social media, and basic digital tools. Lessons are short, friendly, and designed for absolute beginners.\n",
      "LLM suggestion: seniorsmart.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "Trying to build a marketplace for local artists to sell prints, stickers, and small handmade items. Not sure yet how to handle the shipping side, but the idea is to help them reach more people.\n",
      "LLM suggestion: ArtLocal.com\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bd in manual_testing_bd:\n",
    "    print(f\"User Description:\\n{bd}\")\n",
    "    print(f\"LLM suggestion: {propose_domain_name(bd, prompt_improved, model, tokenizer)}\")\n",
    "    print(\"-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f0064a",
   "metadata": {},
   "source": [
    "Now, from the first look, it seems that there are no more improperly formatted domain name suggestions, however, after a quick look at: https://data.iana.org/TLD/tlds-alpha-by-domain.txt one can see that `.amsterdam`, `.tea` or `.educ` not only sound weird, they simply do not exist. Also, some of the suggestions still do not respect the area of operation based on the description. Small detail - there is a mix of lower and upper case letters in the suggestions, which does not look consistent but this could be addressed not only through prompt engineering but also just simply through the function definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b63acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_domain_name(description, prompt, model, tokenizer):\n",
    "    prompt_specific = prompt.format(format_instructions=format_instructions)\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : prompt_specific},\n",
    "        {\"role\" : \"user\", \"content\" : f\"**business_description**:\\n{description}\"}\n",
    "    ]\n",
    "    tokenized_text_processed = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "    tokenized_text_processed = tokenizer([tokenized_text_processed], return_tensors=\"pt\")\n",
    "    tokenized_text_processed = {k: v.to(model.device) for k, v in tokenized_text_processed.items()}\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**tokenized_text_processed, max_new_tokens=1024, do_sample=False)\n",
    "    output_ids = generated_ids[0][len(tokenized_text_processed[\"input_ids\"][0]):]\n",
    "    output_text = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    print(output_text)\n",
    "    output = parse(output_text)\n",
    "    return output.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d73f44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_improved_further = \"\"\"\n",
    "You are a domain-name generation assistant. Your job is to read the user-provided \n",
    "*business_description* and propose ONE realistic, human-feeling domain name that fits the business.\n",
    "\n",
    "Follow these rules carefully:\n",
    "\n",
    "1. If the business description mentions a specific city or country, use the correct ccTLD \n",
    "   for that location (e.g., .uk, .de, .fr, .nl, .es, .pt, .it, .lt, .ca, .us, .au, .jp, etc...).\n",
    "\n",
    "2. If no location is mentioned, choose from REAL modern TLDs ONLY:\n",
    "   .com, .io, .co, .app, .ai, .net, .org, etc...\n",
    "\n",
    "3. The domain MUST:\n",
    "   - sound natural and brandable\n",
    "   - accurately reflect the type of business\n",
    "   - use ONLY real TLDs (no invented extensions)\n",
    "\n",
    "4. Make sure the domain is in the exact format: `name.tld`\n",
    "\n",
    "5. Return ONLY one domain name.\n",
    "\n",
    "6. The final output MUST be valid JSON that matches the schema:\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Do NOT include explanations, reasoning, or extra text. Only return valid JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91e31bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Description:\n",
      "A small studio in Barcelona that designs custom lamps and light fixtures. We mostly work with reclaimed wood and metal. Everything is handmade and produced in small batches.\n",
      "{\"answer\": \"lumina-barca.com\"}\n",
      "LLM suggestion: lumina-barca.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "We’re building an AI tool that helps small online shops write product descriptions automatically. It analyzes the photos and creates short, SEO-friendly copy. Not everything works perfectly yet, but early testers seem to like it.\n",
      "{\"answer\": \"shopdesc.ai\"}\n",
      "LLM suggestion: shopdesc.ai\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "Local dog walking service in Edinburgh. Nothing fancy — just reliable walkers and fair prices. We also send the owners small picture updates after each walk.\n",
      "{\"answer\": \"pawwalk.edinburgh\"}\n",
      "LLM suggestion: pawwalk.edinburgh\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A new app that lets people rent out unused musical instruments to others in their neighborhood. Think of it like Airbnb but for guitars, violins, and keyboards. Still figuring out pricing though.\n",
      "{\"answer\": \"instrumentshare.app\"}\n",
      "LLM suggestion: instrumentshare.app\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "I’m starting an accounting service for freelancers in the US. Mostly bookkeeping, invoicing help, tax reminders, stuff like that. Everything is online and appointments can be booked through the website.\n",
      "{\"answer\": \"freelancerbook.com\"}\n",
      "LLM suggestion: freelancerbook.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A boutique tea brand blending organic loose-leaf teas inspired by traditional Moroccan flavors. Each blend is hand-mixed and sold in small decorative tins.\n",
      "{\"answer\": \"moroccanbloom.com\"}\n",
      "LLM suggestion: moroccanbloom.com\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "We make a browser extension that automatically finds coupon codes for online stores. It applies the best one at checkout. It’s aimed at college students who want quick savings.\n",
      "{\"answer\": \"couponly.app\"}\n",
      "LLM suggestion: couponly.app\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A family-owned bike repair shop located in Amsterdam. We fix all kinds of bikes and offer annual tune-up memberships. Customers can drop off their bikes or request mobile repairs.\n",
      "{\"answer\": \"bikefix.amsterdam\"}\n",
      "LLM suggestion: bikefix.amsterdam\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "An online course platform focused on teaching retirees how to use smartphones, social media, and basic digital tools. Lessons are short, friendly, and designed for absolute beginners.\n",
      "{\"answer\": \"seniorsmart.io\"}\n",
      "LLM suggestion: seniorsmart.io\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "Trying to build a marketplace for local artists to sell prints, stickers, and small handmade items. Not sure yet how to handle the shipping side, but the idea is to help them reach more people.\n",
      "{\"answer\": \"artlocal.co\"}\n",
      "LLM suggestion: artlocal.co\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bd in manual_testing_bd:\n",
    "    print(f\"User Description:\\n{bd}\")\n",
    "    print(f\"LLM suggestion: {propose_domain_name(bd, prompt_improved_further, model, tokenizer)}\")\n",
    "    print(\"-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32830824",
   "metadata": {},
   "source": [
    "Unfortunately, this prompt still doesnt solve some of the issues like `.edinburgh`/`.amsterdam` or suggesting `.com` too often. While this could probably be further addressed by including more examples in the prompt (or simply a choice of a better/bigger model), I will now turn my attention to fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f929b5",
   "metadata": {},
   "source": [
    "## STEP 3: Fine-tuning\n",
    "\n",
    "First things first, to do fine tuning I need to have some dataset. For simplicity, I used chat-gpt to come up with example data. This is reasonable as small experiments with gpt revealed that it can already generate domain suggestions pretty well and thus I am using its knowledge to transfer it into `Qwen3-4b-Instruct-2507`. The dataset contains 214 samples, ±90 of which are non-english. There is a huge focus on having the right TLD based on the description/language while other names I prompted to sound more innovative. Also created evaluation dataset to track training dynamics. \n",
    "\n",
    "For fine-tuning, standard approach in smaller/resource limited situations is to utilize LoRA (`peft` and `trl` packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2553fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d76e7f",
   "metadata": {},
   "source": [
    "We will be using `prompt_improved_further` as a system prompt to set the model for fine-tuning on the right rails. To do this, chat complete has to be changed to include `{% generation %}` tag for SFTConfig to recognize and enable `completions_only_loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed90dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_ft = AutoTokenizer.from_pretrained(NAME)\n",
    "\n",
    "# Overwrite the chat template with a simple one that supports assistant masks\n",
    "tokenizer_ft.chat_template = \"\"\"\\\n",
    "{% for message in messages %}\n",
    "{% if message['role'] == 'system' %}\n",
    "<|im_start|>system\n",
    "{{ message['content'] }}<|im_end|>\n",
    "\n",
    "{% elif message['role'] == 'user' %}\n",
    "<|im_start|>user\n",
    "{{ message['content'] }}<|im_end|>\n",
    "\n",
    "{% elif message['role'] == 'assistant' %}\n",
    "<|im_start|>assistant\n",
    "{{ message['content'] }}<|im_end|>\n",
    "\n",
    "{% endif %}\n",
    "{% endfor %}\n",
    "{% if add_generation_prompt %}\n",
    "<|im_start|>assistant\n",
    "{% generation %}\n",
    "{% endgeneration %}\n",
    "{% endif %}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddc0e4",
   "metadata": {},
   "source": [
    "`assistant` portion has to be formated as this to ensure that system prompt is actually respected and followed and model does not learn to ignore it \n",
    "\n",
    "spoiler: (in my first attempt I actually forgot this and the model would predict string instead of JSON as pretrained instruct model even though system prompt clearly asks for it -> not good)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bee35bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 214/214 [00:00<00:00, 13882.62 examples/s]\n",
      "Map: 100%|██████████| 67/67 [00:00<00:00, 13568.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def formatting_example(example):   \n",
    "    result = {\n",
    "    \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": prompt_improved_further},\n",
    "            {\"role\": \"user\", \"content\": f\"**business_description**:\\n{example['business_description']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f'{{\"answer\": \"{example[\"domain_name\"]}\"}}'}\n",
    "        ]\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "train_raw = load_dataset(\"json\", data_files=['ft.jsonl'], split=\"train\")\n",
    "eval_raw  = load_dataset(\"json\", data_files=['ft_eval.jsonl'],  split=\"train\")\n",
    "\n",
    "train_dataset = train_raw.map(formatting_example, remove_columns=train_raw.column_names)\n",
    "eval_dataset  = eval_raw.map(formatting_example,  remove_columns=eval_raw.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c416c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r = 4,\n",
    "    lora_alpha = 8, # sensible default, lora_alpha=2*lora_rank\n",
    "    lora_dropout = 0.1,\n",
    "    target_modules = 'all-linear',\n",
    "    task_type = TaskType.CAUSAL_LM,\n",
    ")\n",
    "\n",
    "args = SFTConfig(\n",
    "    output_dir='ft_model/',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy='epoch',\n",
    "    max_length=1024,\n",
    "    bf16=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type = 'cosine_with_min_lr',\n",
    "    lr_scheduler_kwargs = {'min_lr_rate' : 0.1},\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=2,\n",
    "    packing=False,\n",
    "    completion_only_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "045971d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristijonasraudys/.pyenv/versions/3.12.7/envs/hostinger-venv/lib/python3.12/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/Users/kristijonasraudys/.pyenv/versions/3.12.7/envs/hostinger-venv/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer_ft,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    args=args,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b98fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
      "/Users/kristijonasraudys/.pyenv/versions/3.12.7/envs/hostinger-venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [81/81 1:05:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.269900</td>\n",
       "      <td>1.592847</td>\n",
       "      <td>1.481140</td>\n",
       "      <td>65152.000000</td>\n",
       "      <td>0.660346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.890500</td>\n",
       "      <td>0.622565</td>\n",
       "      <td>0.621541</td>\n",
       "      <td>130304.000000</td>\n",
       "      <td>0.855931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.417203</td>\n",
       "      <td>0.413008</td>\n",
       "      <td>195456.000000</td>\n",
       "      <td>0.917512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristijonasraudys/.pyenv/versions/3.12.7/envs/hostinger-venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=81, training_loss=1.2922264874717335, metrics={'train_runtime': 3953.8868, 'train_samples_per_second': 0.162, 'train_steps_per_second': 0.02, 'total_flos': 4421166407319552.0, 'train_loss': 1.2922264874717335, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193af1dc",
   "metadata": {},
   "source": [
    "Looking at the table, both the training and validation loss seems to be decreasing reasonably, thus indicating that model has not overfit yet and the improvements (in terms of cross-entropy) are made. Additionally, looking at mean token accuracy, we can see that it grows significantly and thus finetuning has had positive effect on the models capabilities to recommend the domain name (comparing to the simulated datasets). The results are promising, and probably could be increased even further but for the purpose of this preview, they will be left as-is.\n",
    "\n",
    "Now lets load the finetuned model and tokenizer to run through manual testing on the sample of data to compare to previous prompt-engineering approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2551984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  6.24s/it]\n"
     ]
    }
   ],
   "source": [
    "model_ft = AutoModelForCausalLM.from_pretrained('ft_model/checkpoint-81')\n",
    "tokenizer_ft = AutoTokenizer.from_pretrained('ft_model/checkpoint-81')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dab044e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Description:\n",
      "A small studio in Barcelona that designs custom lamps and light fixtures. We mostly work with reclaimed wood and metal. Everything is handmade and produced in small batches.\n",
      "{\"answer\": \"lumina-barcelona.es\"}\n",
      "LLM suggestion: lumina-barcelona.es\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "We’re building an AI tool that helps small online shops write product descriptions automatically. It analyzes the photos and creates short, SEO-friendly copy. Not everything works perfectly yet, but early testers seem to like it.\n",
      "{\"answer\": \"shopdesc.ai\"}\n",
      "LLM suggestion: shopdesc.ai\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "Local dog walking service in Edinburgh. Nothing fancy — just reliable walkers and fair prices. We also send the owners small picture updates after each walk.\n",
      "{\"answer\": \"edinburghdogwalks.co.uk\"}\n",
      "LLM suggestion: edinburghdogwalks.co.uk\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A new app that lets people rent out unused musical instruments to others in their neighborhood. Think of it like Airbnb but for guitars, violins, and keyboards. Still figuring out pricing though.\n",
      "{\"answer\": \"string\"}\n",
      "LLM suggestion: string\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "I’m starting an accounting service for freelancers in the US. Mostly bookkeeping, invoicing help, tax reminders, stuff like that. Everything is online and appointments can be booked through the website.\n",
      "{\"answer\": \"freelancerbookings.us\"}\n",
      "LLM suggestion: freelancerbookings.us\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A boutique tea brand blending organic loose-leaf teas inspired by traditional Moroccan flavors. Each blend is hand-mixed and sold in small decorative tins.\n",
      "{\"answer\": \"marrakechtea.ma\"}\n",
      "LLM suggestion: marrakechtea.ma\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "We make a browser extension that automatically finds coupon codes for online stores. It applies the best one at checkout. It’s aimed at college students who want quick savings.\n",
      "{\"answer\": \"couplebot.app\"}\n",
      "LLM suggestion: couplebot.app\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "A family-owned bike repair shop located in Amsterdam. We fix all kinds of bikes and offer annual tune-up memberships. Customers can drop off their bikes or request mobile repairs.\n",
      "{\"answer\": \"amstelbikes.nl\"}\n",
      "LLM suggestion: amstelbikes.nl\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "An online course platform focused on teaching retirees how to use smartphones, social media, and basic digital tools. Lessons are short, friendly, and designed for absolute beginners.\n",
      "{\"answer\": \"seniordigital.co\"}\n",
      "LLM suggestion: seniordigital.co\n",
      "-----------------------------------------------------\n",
      "\n",
      "User Description:\n",
      "Trying to build a marketplace for local artists to sell prints, stickers, and small handmade items. Not sure yet how to handle the shipping side, but the idea is to help them reach more people.\n",
      "{\"answer\": \"artisanshub.co\"}\n",
      "LLM suggestion: artisanshub.co\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bd in manual_testing_bd:\n",
    "    print(f\"User Description:\\n{bd}\")\n",
    "    print(f\"LLM suggestion: {propose_domain_name(bd, prompt_improved_further, model_ft, tokenizer_ft)}\")\n",
    "    print(\"-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a1755",
   "metadata": {},
   "source": [
    "There is the glaring issue for 4th prompt, where model predicts \"string\" which is not good. Probably finetuning could be improved with more examples, better adjusted training parameters or fallback options, like \"if the prediction is not valid domain name -> use base model, if that is not valid -> use base model to summarize into one word the description and manually add '.com'. Obviously, in this experiment I did not pay attention to model railguards and rely on the knowledge of the base model to control it. \n",
    "\n",
    "However, there is a clear improvement in model's ability to suggest relevant TLD based on the area mentioned in the description (e.g. `.es`, `.co.uk`). Also, to my taste, the suggested domain names are a bit more creative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1c55a",
   "metadata": {},
   "source": [
    "## STEP 4: FAST API implementation\n",
    "Finally, putting this all back together, here is the code to create an API endpoint for the model/agent. The logic is exported to a separate file, `app.py` for simplicity of launching it. To do it, simply run:\n",
    "```bash\n",
    "uvicorn app:app --reload --port 8000\n",
    "```\n",
    "and to access it, load it on your browser via `http://127.0.0.1:8000/docs#` and under `POST /suggest` experiment with how the API works.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df566670",
   "metadata": {},
   "source": [
    "## STEP 5: Final remarks\n",
    "Overall, this repository gives a preview of how I would tacke this task. It took around 4 hours of work (+2-3 hours for model training and inference) to create this. Here are pros and cons of **promp-engineering** and **fine-tuning** approaches:\n",
    "\n",
    "**prompt-engineering**\n",
    "\n",
    "*pros*:\n",
    "- very fast to implement\n",
    "- very flexible in terms of the possibility to produce different results\n",
    "- great for experimentation and setting up a baseline\n",
    "- internal knowledge could be improved via providing additional information or examples\n",
    "\n",
    "*cons*:\n",
    "- while additional information could be added in the prompt, the more different things you put there, the higher the risk of the model being unable to focus/perform on the task\n",
    "- small changes in the prompt can have significant changes in the model output without clear understanding of why that happens, i.e. stability\n",
    "\n",
    "\n",
    "**fine-tuning**\n",
    "\n",
    "*cons*:\n",
    "- needs dataset\n",
    "- takes much longer to set-up, including hyperparameter tuning and the training itself\n",
    "- risk of overfitting\n",
    "- potential for catastrophic forgetting on previous knowledge\n",
    "- with standard implementations, model is bound to become somewhat more restrictve and more task-focused\n",
    "\n",
    "\n",
    "*pros*:\n",
    "- can achieve much better results than prompt-engineering\n",
    "- much more customizable control over what and how the model outputs should look like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33e488",
   "metadata": {},
   "source": [
    "As for the future suggestions:\n",
    "1) to transform the llm into an agent with tools; one of the tools could check if the website that is recommended already exists and if so, request the model to regenerate another suggestion.\n",
    "2) output list of suggestions so that the user can choose.\n",
    "3) spend more time to identify from the description the target population of the website and take it into account when proposing the domain name.\n",
    "4) explore slightly bigger models and play with the hyperparameters.\n",
    "5) expand the training dataset with more examples, or, even better, have human writters come up with a new, human-like dataset that would give a much more authentic flavour to the finetuned model, as some of the suggestions are still bland and predictable. Ofcourse, this could be also done using LLM to generate the data but the level of control should be very high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hostinger-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
